{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "de864c1a-3913-45a7-92fc-de72bd57cc98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-03-27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.002746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Dividends  Stock Splits\n",
       "Date                               \n",
       "2014-03-27        0.0      2.002000\n",
       "2015-04-27        0.0      1.002746\n",
       "2022-07-18        0.0     20.000000"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "tickers = yf.Tickers('msft aapl goog')\n",
    "\n",
    "# access each ticker using (example)\n",
    "tickers.tickers['MSFT'].info\n",
    "tickers.tickers['AAPL'].history(period=\"1mo\")\n",
    "tickers.tickers['GOOG'].actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e36fad0d-6358-4e46-88b1-b40f34db0401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  2 of 2 completed\n",
      "\n",
      "1 Failed download:\n",
      "- AAPPPLL: No data found, symbol may be delisted\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Adj Close</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Close</th>\n",
       "      <th colspan=\"2\" halign=\"left\">High</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Low</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Open</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>AAPPPLL</th>\n",
       "      <th>SPY</th>\n",
       "      <th>AAPPPLL</th>\n",
       "      <th>SPY</th>\n",
       "      <th>AAPPPLL</th>\n",
       "      <th>SPY</th>\n",
       "      <th>AAPPPLL</th>\n",
       "      <th>SPY</th>\n",
       "      <th>AAPPPLL</th>\n",
       "      <th>SPY</th>\n",
       "      <th>AAPPPLL</th>\n",
       "      <th>SPY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-02-11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>433.428314</td>\n",
       "      <td>NaN</td>\n",
       "      <td>440.459991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>451.609985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>438.940002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>449.410004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>153214600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>432.011322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>439.019989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>441.600006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>435.339996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>439.920013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123006300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>438.978333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>446.100006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>446.279999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>443.179993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>443.730011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88482700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>439.470337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>446.600006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>448.059998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>441.940002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>443.929993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84863600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>430.082642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>437.059998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>446.570007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>436.420013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>443.220001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102259100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>409.829987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>409.829987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>411.290009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>408.100006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>409.790009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60295300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>415.190002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>415.190002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>416.489990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>407.570007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>408.869995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90990700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-08</th>\n",
       "      <td>NaN</td>\n",
       "      <td>410.649994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>410.649994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>414.529999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>409.929993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>413.130005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76227500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-09</th>\n",
       "      <td>NaN</td>\n",
       "      <td>407.089996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>407.089996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>414.570007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>405.809998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>414.410004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78694900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>408.040009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>408.040009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>408.440002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>405.010010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>405.859985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70738000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Adj Close               Close                High              \\\n",
       "             AAPPPLL         SPY AAPPPLL         SPY AAPPPLL         SPY   \n",
       "Date                                                                       \n",
       "2022-02-11       NaN  433.428314     NaN  440.459991     NaN  451.609985   \n",
       "2022-02-14       NaN  432.011322     NaN  439.019989     NaN  441.600006   \n",
       "2022-02-15       NaN  438.978333     NaN  446.100006     NaN  446.279999   \n",
       "2022-02-16       NaN  439.470337     NaN  446.600006     NaN  448.059998   \n",
       "2022-02-17       NaN  430.082642     NaN  437.059998     NaN  446.570007   \n",
       "...              ...         ...     ...         ...     ...         ...   \n",
       "2023-02-06       NaN  409.829987     NaN  409.829987     NaN  411.290009   \n",
       "2023-02-07       NaN  415.190002     NaN  415.190002     NaN  416.489990   \n",
       "2023-02-08       NaN  410.649994     NaN  410.649994     NaN  414.529999   \n",
       "2023-02-09       NaN  407.089996     NaN  407.089996     NaN  414.570007   \n",
       "2023-02-10       NaN  408.040009     NaN  408.040009     NaN  408.440002   \n",
       "\n",
       "               Low                Open              Volume             \n",
       "           AAPPPLL         SPY AAPPPLL         SPY AAPPPLL        SPY  \n",
       "Date                                                                   \n",
       "2022-02-11     NaN  438.940002     NaN  449.410004     NaN  153214600  \n",
       "2022-02-14     NaN  435.339996     NaN  439.920013     NaN  123006300  \n",
       "2022-02-15     NaN  443.179993     NaN  443.730011     NaN   88482700  \n",
       "2022-02-16     NaN  441.940002     NaN  443.929993     NaN   84863600  \n",
       "2022-02-17     NaN  436.420013     NaN  443.220001     NaN  102259100  \n",
       "...            ...         ...     ...         ...     ...        ...  \n",
       "2023-02-06     NaN  408.100006     NaN  409.790009     NaN   60295300  \n",
       "2023-02-07     NaN  407.570007     NaN  408.869995     NaN   90990700  \n",
       "2023-02-08     NaN  409.929993     NaN  413.130005     NaN   76227500  \n",
       "2023-02-09     NaN  405.809998     NaN  414.410004     NaN   78694900  \n",
       "2023-02-10     NaN  405.010010     NaN  405.859985     NaN   70738000  \n",
       "\n",
       "[251 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yf.download(tickers = \"SPY AAPPPLL\",  # list of tickers\n",
    "            period = \"1y\",         # time period\n",
    "            interval = \"1d\",       # trading interval\n",
    "            ignore_tz = True,      # ignore timezone when aligning data from different exchanges?\n",
    "            prepost = False )      # download pre/post market hours data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "d5073e30-0906-4460-a830-1e87ba6bdc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class stock_data:\n",
    "    import yfinance as yf\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import scipy.stats\n",
    "    \n",
    "    def __init__(self, ticker, start_date, end_date, risk_free_rate=0):\n",
    "        self.ticker = ticker\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.risk_free_rate = risk_free_rate\n",
    "        self.data = yf.download(self.ticker, self.start_date, self.end_date)\n",
    "        self.data['Daily Return'] = self.data['Adj Close'].pct_change(1)\n",
    "        self.sortino_ratio = None\n",
    "        self.sharpe_ratio = None\n",
    "        self.probabilistic_sharpe_ratio = None\n",
    "        \n",
    "        \n",
    "    def info(self):\n",
    "        print(f'Ticker: {self.ticker}, start_date: {self.start_date}, end_date:{self.end_date}')\n",
    "    \n",
    "    def _compute_sharpe_ratio(self):\n",
    "        mean_return = self.data.dropna()['Daily Return'].mean()\n",
    "        std = self.data.dropna()['Daily Return'].std()\n",
    "        self.sharpe_ratio = (mean_return-self.risk_free_rate) / std\n",
    "        del mean_return\n",
    "        del std\n",
    "    \n",
    "        \n",
    "    def get_sharpe_ratio(self, daily=True):\n",
    "        if not self.sharpe_ratio:\n",
    "            self._compute_sharpe_ratio()\n",
    "        if daily:\n",
    "            return self.sharpe_ratio\n",
    "        else:\n",
    "            return self.sharpe_ratio * (252 ** 0.5)\n",
    "    \n",
    "    def _compute_sortino_ratio(self, target=0):\n",
    "        df = self.data.dropna()\n",
    "        mean_return = df['Daily Return'].mean()\n",
    "        downside = df[df['Daily Return'] < target]['Daily Return']\n",
    "        std = downside.std()\n",
    "        self.sortino_ratio = (mean_return-self.risk_free_rate) / std\n",
    "        del df      \n",
    "        \n",
    "    def get_sortino_ratio(self, daily=True):\n",
    "        if not self.sortino_ratio:\n",
    "            self._compute_sortino_ratio()\n",
    "        if daily:\n",
    "            return self.sortino_ratio\n",
    "        else:\n",
    "            return self.sortino_ratio * (252 ** 0.5)\n",
    "    \n",
    "    def _compute_probabilistic_sharpe_ratio(self, benchmark=0):\n",
    "        if not self.sortino_ratio:\n",
    "            self._compute_sortino_ratio()\n",
    "        import scipy.stats\n",
    "        skew = scipy.stats.skew(self.data[\"Daily Return\"].dropna())\n",
    "        # Use fisher kurtosis\n",
    "        kurtosis = scipy.stats.kurtosis(self.data[\"Daily Return\"].dropna(), fisher=True)  \n",
    "        n = len(self.data)\n",
    "        std = ( (1 / (n-1)) * (1 + 0.5 * self.sortino_ratio**2 - skew * self.sortino_ratio + (kurtosis / 4) * self.sortino_ratio**2))**0.5\n",
    "        ratio = (self.sortino_ratio - benchmark) / std\n",
    "        self.probabilistic_sharpe_ratio = scipy.stats.norm.cdf(ratio)\n",
    "\n",
    "    def get_probabalistic_sharpe_ratio(self, daily=True):\n",
    "        if not self.probabilistic_sharpe_ratio:\n",
    "            self._compute_probabilistic_sharpe_ratio()\n",
    "        if daily:\n",
    "            return self.probabilistic_sharpe_ratio\n",
    "        else:\n",
    "            return self.probabilistic_sharpe_ratio * (252 ** 0.5)\n",
    "\n",
    "    \n",
    "    def plot_daily_returns(self, kind='line', alpha=None):\n",
    "        if kind == 'line':\n",
    "            self.data.dropna()['Daily Return'].plot(kind=kind, label=self.ticker)\n",
    "            plt.legend()\n",
    "        elif kind =='hist':\n",
    "            self.data.dropna()['Daily Return'].plot(kind=kind, bins=100, label=self.ticker, alpha=alpha)\n",
    "            plt.legend()\n",
    "        else:\n",
    "            raise TypeError(f'Plot Kind of {kind} is not supported. Only line and hist kinds are supported')\n",
    "    \n",
    "    def plot_cumulative_daily_return_rate(self):\n",
    "        cumul_return = (1 + self.data['Daily Return'].dropna()).cumprod() - 1\n",
    "        (cumul_return * 100).plot()\n",
    "        plt.ylabel(\"Cumulative Return as %\")\n",
    "            \n",
    "class stock_comp:\n",
    "    def __init__(self, tickers, start_date, end_date):\n",
    "        from numpy import log\n",
    "        self.tickers = tickers\n",
    "        self.ticker_dict = {}\n",
    "        self.mc_portfolio_returns = None\n",
    "        self.mc_portfolio_vol = None\n",
    "        self.mc_weights = None\n",
    "        self.mc_sharpe_ratios = None\n",
    "        \n",
    "        for ticker in tickers:\n",
    "            stock_data_obj_ = stock_data(ticker, start_date, end_date)\n",
    "            if len(stock_data_obj_.data) != 0:\n",
    "                self.ticker_dict[ticker] = stock_data_obj_\n",
    "            else:\n",
    "                print(f'Unable to retrieve stock data for ticker: {ticker}. Excluding this ticker from analysis')\n",
    "                self.tickers.remove(ticker)\n",
    "\n",
    "        \n",
    "        self.n = len(self.tickers)\n",
    "        self.equal_weights = [(1 / self.n)] * self.n\n",
    "        \n",
    "        self.adj_close = pd.concat([df.data['Adj Close'] for df in self.ticker_dict.values()], axis=1)\n",
    "        self.adj_close.columns = self.tickers\n",
    "        \n",
    "        self.rets = pd.concat([df.data['Daily Return'].dropna() for df in self.ticker_dict.values()], axis=1)\n",
    "        self.rets.columns = self.tickers\n",
    "        \n",
    "        self.log_rets = log(self.adj_close/self.adj_close.shift(1))\n",
    "        self.log_rets_cov = self.log_rets.cov()\n",
    "        \n",
    "    def get_ticker_dict(self):\n",
    "        return self.ticker_dict\n",
    "    \n",
    "    def get_daily_returns(self):\n",
    "        return self.rets\n",
    "    \n",
    "    def plot_daily_returns(self, kind='line', alpha=None):\n",
    "        if kind == 'line':\n",
    "            self.rets.plot(kind=kind)\n",
    "        elif kind =='hist':\n",
    "            self.rets.plot(kind=kind, bins=100, alpha=alpha)\n",
    "            plt.legend()\n",
    "        else:\n",
    "            raise TypeError(f'Plot Kind of {kind} is not supported. Only line and hist kinds are supported')\n",
    "    \n",
    "    def _gen_random_weights(self):\n",
    "        import numpy as np\n",
    "        weights = np.random.random(self.n)\n",
    "        return weights/ np.sum(weights)\n",
    "    \n",
    "    def _calculate_returns(self, weights, log_rets):\n",
    "        from numpy import sum\n",
    "        return sum(log_rets.mean()*weights) * 252 #Annualized Returns\n",
    "    \n",
    "    def _calculate_volatility(self, weights, log_rets_cov):\n",
    "        from numpy import dot, sqrt\n",
    "        annualized_cov = dot(log_rets_cov*252,weights)\n",
    "        vol = dot(weights.transpose(),annualized_cov)\n",
    "        return sqrt(vol)\n",
    "    \n",
    "    def _plot_bullet_graph(self, mc_portfolio_returns, mc_portfolio_vol, mc_sharpe_ratios):\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.figure(dpi=200,figsize=(10,5))\n",
    "        plt.scatter(mc_portfolio_vol,mc_portfolio_returns,c=mc_sharpe_ratios)\n",
    "        plt.ylabel('EXPECTED RETURNS')\n",
    "        plt.xlabel('EXPECTED VOLUME')\n",
    "        plt.colorbar(label=\"SHARPE RATIO\")\n",
    "\n",
    "        \n",
    "    def run_monte_carlo_simulation(self, n_simulations=1000):\n",
    "        from numpy import array\n",
    "        self.mc_portfolio_returns = []\n",
    "        self.mc_portfolio_vol = []\n",
    "        self.mc_weights = []\n",
    "        for sim in range(n_simulations):\n",
    "            # This may take awhile!\n",
    "            weights = self._gen_random_weights()\n",
    "            self.mc_weights.append(weights)\n",
    "            self.mc_portfolio_returns.append(self._calculate_returns(weights,self.log_rets))\n",
    "            self.mc_portfolio_vol.append(self._calculate_volatility(weights,self.log_rets_cov))\n",
    "            \n",
    "        self.mc_sharpe_ratios = array(self.mc_portfolio_returns)/array(self.mc_portfolio_vol)\n",
    "        self._plot_bullet_graph(self.mc_portfolio_returns, self.mc_portfolio_vol, self.mc_sharpe_ratios)\n",
    "    \n",
    "    def minimization_search_optimal_weights(self):\n",
    "        from scipy.optimize import minimize\n",
    "        from numpy import sum \n",
    "        def function_to_minimize(weights):\n",
    "            # Note -1* because we need to minimize this\n",
    "            # Its the same as maximizing the positive sharpe ratio\n",
    "            return -1 * (self._calculate_returns(weights,self.log_rets)/self._calculate_volatility(weights,self.log_rets_cov))\n",
    "        bounds = tuple((0,1) for n in range(self.n))\n",
    "        sum_constraint = ({'type': 'eq', 'fun': lambda weights: sum(weights)-1})\n",
    "        self.minimization_search_results_ = minimize(fun=function_to_minimize,x0=self.equal_weights,bounds=bounds,constraints=sum_constraint)\n",
    "        return self.minimization_search_results_\n",
    "    \n",
    "    def _calculate_efficient_frontier(self):\n",
    "        pass\n",
    "    \n",
    "    def _plot_efficient_frontier(self):\n",
    "        pass\n",
    "    \n",
    "    def get_efficient_frontier_weights(self):\n",
    "        pass\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "19a8caeb-436a-48fc-a51c-20b163f655ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "my_stock = stock('COST', '2017-01-01', '2021-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "7af6868d-c038-4bf5-9f59-90db8589aa57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "tickers = ['AAPL', 'COST', 'TSLA', 'ETSY']\n",
    "start_date = '2017-01-01'\n",
    "end_date = '2021-01-01'\n",
    "\n",
    "comp = stock_comp(tickers, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "b672873f-6efb-4473-a560-00278f7e8b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: -1.6438617821905819\n",
       "     jac: array([-8.49515200e-05,  1.15633011e-05, -2.19598413e-04,  2.54139304e-04])\n",
       " message: 'Optimization terminated successfully'\n",
       "    nfev: 32\n",
       "     nit: 6\n",
       "    njev: 6\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([0.22701512, 0.37772954, 0.18049223, 0.21476311])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp.minimization_search_optimal_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48988674-ba40-4a11-b16e-bd5529cbc7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
